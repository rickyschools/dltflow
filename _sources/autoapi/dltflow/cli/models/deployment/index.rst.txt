:py:mod:`dltflow.cli.models.deployment`
=======================================

.. py:module:: dltflow.cli.models.deployment

.. autoapi-nested-parse::

   dltflow.models.deployment.py
   ------------------------------
   This module is basically a copy and paste of the dbx.models.deployment module with some modifications to support
   the dltflow deployment configuration file format. All the classes and methods are the same as in the original module,
   but with names prefixed with "DLTFlow" and the appropriate return types and annotations added.

   There are some additional classes defined to extend existing classes, like Pipeline.

   The Pipeline is extended with a tasks attribute, which is an instance of the DLTFlowTasks class.
   The DLTFlowTasks class provides an extension to the Databricks Pipeline API structure by allowing
   for the definition of PySpark tasks and parameters, as well as custom dependencies needed to
   build a DLT Pipeline.

   These task objects are used to dynamically build a notebook, that references (via imports) the necessary
   code and configuration files. This is the magic sauce to push Python code into a Databricks DLT pipeline.

   This pattern allows to maximize the Software Engineering best practices, like DRY, and to keep
   the codebase clean and maintainable, while also allowing engineering teams to leverage the power of Databricks
   DLT for their pipeline processing needs.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   dltflow.cli.models.deployment.DLTFlowDependency
   dltflow.cli.models.deployment.DLTFlowSparkPythonTask
   dltflow.cli.models.deployment.DLTFlowTasks
   dltflow.cli.models.deployment.DLTFlowPipeline




Attributes
~~~~~~~~~~

.. autoapisummary::

   dltflow.cli.models.deployment.deployment_source


.. py:class:: DLTFlowDependency


   Bases: :py:obj:`dbx.models.workflow.common.flexible.FlexibleModel`

   A dependency for a DLTFlow task.

   .. py:attribute:: whl
      :type: Optional[str]

      

   .. py:attribute:: pypi
      :type: Optional[dbx.models.workflow.common.libraries.PythonPyPiLibrary]

      

   .. py:method:: validate(values)
      :classmethod:

      Ensure that at least one of whl or pypi is provided, but not both.


   .. py:method:: get_dependency()

      Return the dependency as a string.



.. py:class:: DLTFlowSparkPythonTask


   Bases: :py:obj:`dbx.models.workflow.common.task.SparkPythonTask`

   A Pydantic model for a DLTFlow PySpark task.

   .. py:attribute:: python_file
      :type: str

      

   .. py:attribute:: parameters
      :type: List[str]

      

   .. py:method:: provide_items()

      Return the task items as a dictionary.



.. py:class:: DLTFlowTasks


   Bases: :py:obj:`pydantic.v1.BaseModel`

   A Pydantic model for a DLTFlow tasks object.

   .. py:attribute:: items
      :type: List[DLTFlowSparkPythonTask]

      

   .. py:attribute:: dependencies
      :type: List[DLTFlowDependency]

      

   .. py:method:: get_items()

      Return the task items as a list of dictionaries.


   .. py:method:: get_dependencies()

      Return the dependencies as a list of strings.



.. py:class:: DLTFlowPipeline


   Bases: :py:obj:`dbx.models.workflow.common.pipeline.Pipeline`

   A Pydantic model for a DLTFlow pipeline.

   .. py:attribute:: workflow_type
      :type: Literal[pipeline]

      

   .. py:attribute:: tasks
      :type: DLTFlowTasks

      

   .. py:method:: get_tasks()

      Return the tasks as a list of dictionaries.



.. py:data:: deployment_source

   

